project: "PPO"
dtype: "bfloat16"
seed: 42
data:
  rm_dataset: "imdb"
  ppo_dataset: "imdb"
training:
  rm:
    tokenizer_name_or_path: 'facebook/opt-350m'
    model_name_or_path: 'src/ckpt/rm/reward_model_epoch02'
    states_file: 'src/ckpt/rm/reward_model_epoch02/states.pt'
    learning_rate: 5.0e-5
    weight_decay: 0
    betas: [0.9, 0.999]
    max_norm: 1.0
    batch_size: 6
    eval_batch_size: 64
    enable_memory_efficient_adamw: true
    gradient_accumulation_steps: 16
    num_train_epochs: 3
    num_workers: 10,
    max_len: 1024
    max_eval_size_per_category: 640
    eval_interval: 500
  ppo:
    tokenizer_name_or_path: 'TinyLlama/TinyLlama-1.1B-step-50K-105b'
    model_name_or_path: 'TinyLlama/TinyLlama-1.1B-step-50K-105b'
    pretrained_reward_model_path: 'src/ckpt/rm/reward_model_epoch02'
    states_file: 'src/ckpt/ppo/ppo_epoch02_states.pt'
    min_num_words: 15
    num_input_tokens: 10
    batch_size: 8
    learning_rate: 5.0e-5
    weight_decay: 0
    betas: [0.9, 0.999]    
    enable_memory_efficient_adamw: true
    num_train_epochs: 3
    generation_kwargs: 
      min_length: -1
      top_k: 0.0
      top_p: 1.0
      do_sample: True
      max_new_tokens: 128
    beta: 0.2
    clip_lower_ratio: 0.2
    clip_higher_ratio: 0.3
    value_loss_coeff: 0.5
    value_cliprange: 1.0
    gradient_accumulation_steps: 4
    max_norm: 1.0